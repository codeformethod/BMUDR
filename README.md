Code for Adaptive Bigraph-Based Multi-view Unsupervised Dimensionality Reduction

Platform: The experiments are implemented on a Windows 10 desktop computer equipped with a 3.6GHz Intel Core i7-7700 CPU, 64 GB RAM, and Matlab R2018a (64bit). Implementation details: The implementation of the proposed method is as follows. The input includes the multi-view data matrix {X_v}v=1^nv, dimensionality d' of the embedding, anchor number m, regularization scalar \gamma, and trade-off parameters \alpha and \beta. In the beginning, we initialize weights {w_v}v=1^nv and multi-view consistent anchor-based similarity matrix Z as w_v=1/nv and z_{ij}=1/m. Next, we update the variables one by one until the target value converges. Firstly, we update the view-specific anchor set U_v according to Eq. (6). Secondly, we update embeddings of the dataset and anchor set by conducting singular value decomposition on the regularized anchor similarity matrix (D_F)^(-1/2)Z^T(D_G)^(-1/2), where D_F and D_G are two diagonal degree matrices whose diagonal elements are (d_F){jj}=\sum_i(z{ij}) and (d_G){ii}=\sum_j(z{ij}), respectively. The embeddings of the dataset and anchor set are formed by the d' leading left and right singular vectors of (D_F)^(-1/2)Z^T(D_G)^(-1/2). Thirdly, we update Z by row by applying the augmented Lagrangian multiplier method to solve the problem in Eq. (12). Fourthly, we update {w_v}v=1^nv according to Eq. (26). The iterative updating is not terminated until the difference in objective value is less than 1e-6. Parameter settings: we explore \alpha and \beta in the grid of {10‚àí3, 10‚àí2, 10‚àí1, 10^0, 10^1, 10^2, 10^3}, and \gamma in {1.2, 1.5, 1.8, 2, 4, 6, 8, 10}. We learn 20-dimensional embeddings, with ùëö set to 0.1ùëõ, except in YALE where it is set to 0.122ùëõ for normal experiments.
